!pip install nltk scikit-learn spacy wordcloud matplotlib
!python -m spacy download en_core_web_sm

import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import PorterStemmer, WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
import spacy
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Download NLTK data
nltk.download('punkt', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('punkt_tab', quiet=True)

# Sample text
text = "Apple Inc. was founded by Steve Jobs. Google and Microsoft are tech giants. Python programming is amazing!"

print("Original Text:")
print(text, "\n")

# 1. TOKENIZATION

print("1. TOKENIZATION:")
words = word_tokenize(text)
sentences = sent_tokenize(text)
print(f"Words: {words[:10]}")
print(f"Sentences: {sentences}\n")


# 2. STEMMING & LEMMATIZATION

print("2. STEMMING & LEMMATIZATION:")
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()

sample_words = ['running', 'companies', 'better', 'programming']
for word in sample_words:
    print(f"{word} → Stem: {stemmer.stem(word)}, Lemma: {lemmatizer.lemmatize(word)}")
print()


# 3. SCIKIT-LEARN (TF-IDF)

print("3. SCIKIT-LEARN TF-IDF:")
docs = ["Python is great", "NLP is amazing", "Machine learning rocks"]
vectorizer = TfidfVectorizer()
tfidf = vectorizer.fit_transform(docs)
print(f"Features: {vectorizer.get_feature_names_out()}")
print(f"Matrix shape: {tfidf.shape}\n")


# 4. SPACY (POS & NER)

print("4. SPACY - POS & NER:")
nlp = spacy.load('en_core_web_sm')
doc = nlp(text)

print("POS Tags:")
for token in list(doc)[:8]:
    print(f"  {token.text}: {token.pos_}")

print("\nNamed Entities:")
for ent in doc.ents:
    print(f"  {ent.text} → {ent.label_}")
print()


# 5. WORD CLOUD

print("5. WORD CLOUD:")
wordcloud = WordCloud(width=600, height=300, background_color='white').generate(text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud')
plt.tight_layout()
plt.savefig('wordcloud.png', dpi=150)
plt.show()
print(" Word cloud saved!\n")


# 6. SENTENCE SEGMENTATION

print("6. SENTENCE SEGMENTATION:")
for i, sent in enumerate(sentences, 1):
    print(f"  Sentence {i}: {sent}")

print("\n All NLP operations complete!")
